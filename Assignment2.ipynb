{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0Iyg6btLW9M"
   },
   "source": [
    "#  Assignment 2 - Transfer Learning and Data Augmentation ðŸ’¬\n",
    "\n",
    "Welcome to the **second assignment** for the **CS-552: Modern NLP course**!\n",
    "\n",
    "> - ðŸ˜€ Name: **Mathieu Desponds**\n",
    "> - âœ‰ï¸ Email: **mathieu.desponds@epfl.ch**\n",
    "> - ðŸªª SCIPER: **283229**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_XjnQhbFIJUu"
   },
   "source": [
    "<div style=\"padding:15px 20px 20px 20px;border-left:3px solid green;background-color:#e4fae4;border-radius: 20px;\">\n",
    "\n",
    "## **Assignment Description**\n",
    "- In the first part of this assignment, you will need to implement training (fine-tuning) and evaluation of a pre-trained language model ([DistilBERT](https://huggingface.co/docs/transformers/model_doc/distilbert) ), on natural language inference (NLI) task for recognizing textual entailment (RTE).\n",
    "\n",
    "- Following the first finetuning task, you will need to identify the shortcut (i.e. some salient or toxic features) that the model learnt for the specific task. \n",
    "\n",
    "- For part-3, you are supposed to annotate 100 randomly assigned test datapoints as ground-truth labels. Additionally, the cross annotation should be conducted by another one or two annotators, and you will learn about how to calculate the agreement statistics as a significant characteristic reflecting the quality of a collected dataset.\n",
    "\n",
    "- For part-4, since the human annotation is quite time- and effort-consuming, there are plenty of ways to get silver-labels from automatic labeling to augment the dataset scale. We provide the reference to some simple methods (EDA and Back Translation) but you are encouraged to explore other advanced mechanisms. You will evaluate the improvement of your model performance by using your data augmentation method.\n",
    "\n",
    "For each part, you will need to complete the code in the corresponding `.py` files (`nli.py` for Part-1, `shortcut.py` for Part-2, `eda.py` for Part-4). You will be provided with the function descriptions and detailed instructions about the code snippet you need to write.\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "- **[PART 1: Model Finetuning for NLI](#1)**\n",
    "    - [1.1 Data Processing](#11)\n",
    "    - [1.2 Model Training and Evaluation](#12)\n",
    "- **[PART 2: Identify Model Shortcut](#2)**\n",
    "    - [2.1 Word-Pair Pattern Extraction](#21)\n",
    "    - [2.2 Distill Potentially Useful Patterns](#22)\n",
    "    - [2.3 Case Study](#23)\n",
    "- **[PART 3: Annotate New Data](#3)**\n",
    "    - [3.1 Write an Annotation Guideline](#31)\n",
    "    - [3.2 Annotate Your 100 Datapoints with Partner(s)](#32)\n",
    "    - [3.3 Agreement Measure](#33)\n",
    "    - [3.4 Robustness Check](#34)\n",
    "- **[PART 4: Data Augmentation](#4)**\n",
    "    \n",
    "### Deliverables\n",
    "\n",
    "- âœ… This jupyter notebook\n",
    "- âœ… `nli.py` file\n",
    "- âœ… `shortcut.py` file\n",
    "- âœ… Finetuned DistilBERT models for NLI task (Part 1 and Part 4)\n",
    "- âœ… Annotated and cross-annotated data files (Part 3)\n",
    "- âœ… New dataset from data augmentation (Part 4)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lluaZwaS-0v9"
   },
   "source": [
    "### Google Colab Setup\n",
    "If you are using Google Colab notebook for this assignment, you will need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section.\n",
    "\n",
    "Run the following cell to mount your Google Drive. Follow the popped window, sign in to your Google account. (The same account you used to store this notebook!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28370,
     "status": "ok",
     "timestamp": 1680726166738,
     "user": {
      "displayName": "Prophecy Gaming PrG",
      "userId": "14056781264544618042"
     },
     "user_tz": -120
    },
    "id": "VfVHqiSvK1aB",
    "outputId": "f6006408-ae9e-4e71-f245-f66650b25603"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opCteyIv-_kS"
   },
   "source": [
    "Now first click the 4th left-side bar (named Files), then click the 2nd bar popped under Files column (named Refresh), under \"/drive/MyDrive/\" find the Assignment 2 folder that you uploaded to your Google Drive, copy its path and fill it in below. If everything is working correctly, then running the folowing cell should print the filenames from the assignment:\n",
    "\n",
    "```\n",
    "['Assignment2.ipynb', 'requirements.txt', 'runs', 'predictions', 'nli_data', 'testA2.py', 'nli.py', 'shortcut.py']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 649,
     "status": "ok",
     "timestamp": 1680726167345,
     "user": {
      "displayName": "Prophecy Gaming PrG",
      "userId": "14056781264544618042"
     },
     "user_tz": -120
    },
    "id": "agEgK0kdrUdT",
    "outputId": "d41f89d9-949c-4a78-c40c-e9d57f16b5e6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# TODO: Fill in the path where you download the Assignment folder into\n",
    "ROOT_PATH = \"./drive/MyDrive/A2\" # Replace with your directory to A2 folder\n",
    "print(os.listdir(ROOT_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5mABwvHy5-e"
   },
   "source": [
    "Before we start, we also need to run some boilerplate code to set up our environment, same as previous assignments. You'll need to rerun this setup code each time you start the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 163975,
     "status": "ok",
     "timestamp": 1680726344482,
     "user": {
      "displayName": "Prophecy Gaming PrG",
      "userId": "14056781264544618042"
     },
     "user_tz": -120
    },
    "id": "ZhJT7Fo4_D1f",
    "outputId": "2a0f1d98-87b6-4314-a322-4aa9766754d0"
   },
   "outputs": [],
   "source": [
    "requirements = ROOT_PATH + \"/requirements.txt\"\n",
    "!pip install torch==1.13.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "!pip install -r {requirements}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUw9ycDa21dl"
   },
   "source": [
    "\n",
    "Run this cell to load the autoreload extension. This allows us to edit .py source files, and re-import them into the notebook for a seamless editing and debugging experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 110,
     "status": "ok",
     "timestamp": 1680726344524,
     "user": {
      "displayName": "Prophecy Gaming PrG",
      "userId": "14056781264544618042"
     },
     "user_tz": -120
    },
    "id": "3PVAoLPQ_I7c",
    "outputId": "58c00ec1-005a-4fda-d8d5-5444b2d8ad48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 8993,
     "status": "ok",
     "timestamp": 1680726353437,
     "user": {
      "displayName": "Prophecy Gaming PrG",
      "userId": "14056781264544618042"
     },
     "user_tz": -120
    },
    "id": "mA1Qk-_K_LRm"
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import jsonlines\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_constant_schedule_with_warmup\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csa48DhDr0td"
   },
   "source": [
    "Once you have successfully mounted your Google Drive and located the path to this assignment, run the following cell to allow us to import from the `.py` files of this assignment. If it works correctly, it should print the message:\n",
    "\n",
    "```\n",
    "Hello A2!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4414,
     "status": "ok",
     "timestamp": 1680726357794,
     "user": {
      "displayName": "Prophecy Gaming PrG",
      "userId": "14056781264544618042"
     },
     "user_tz": -120
    },
    "id": "U10S-b9BrNxj",
    "outputId": "2bd95be5-08b2-42aa-986e-e9f52462dd2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello A2!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(ROOT_PATH)\n",
    "\n",
    "from testA2 import hello_A2\n",
    "hello_A2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnWpzntscWUE"
   },
   "source": [
    "Note that if CUDA is not enabled, `torch.cuda.is_available()` will return False and this notebook will fallback to CPU mode.\n",
    "\n",
    "The global variables `dtype` and `device` will control the data types throughout this assignment.\n",
    "\n",
    "We will be using `torch.float = torch.float32` for all operations.\n",
    "\n",
    "Please refer to https://pytorch.org/docs/stable/tensor_attributes.html#torch-dtype for more details about data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 816,
     "status": "ok",
     "timestamp": 1680726358599,
     "user": {
      "displayName": "Prophecy Gaming PrG",
      "userId": "14056781264544618042"
     },
     "user_tz": -120
    },
    "id": "Rqb9cwkNIEHr",
    "outputId": "ac065f4a-103a-48ef-dad6-8ab47bd36b10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good to go!\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('Good to go!')\n",
    "else:\n",
    "    print('Please set GPU via Edit -> Notebook Settings.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MSpYuMcyHfl"
   },
   "source": [
    "### Local Setup\n",
    "If you skip Google Colab setup, you still need to fill in the path where you download the Assignment folder, and install required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 46,
     "status": "aborted",
     "timestamp": 1680726175737,
     "user": {
      "displayName": "Prophecy Gaming PrG",
      "userId": "14056781264544618042"
     },
     "user_tz": -120
    },
    "id": "QQHs7vHhydij"
   },
   "outputs": [],
   "source": [
    "ROOT_PATH = \"./\" # Replace with your directory to A2 folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 48,
     "status": "aborted",
     "timestamp": 1680726175739,
     "user": {
      "displayName": "Prophecy Gaming PrG",
      "userId": "14056781264544618042"
     },
     "user_tz": -120
    },
    "id": "IKeGSDpAyigE"
   },
   "outputs": [],
   "source": [
    "requirements = ROOT_PATH + \"/requirements.txt\"\n",
    "!pip install -r {requirements}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "C6b-Enimyywz",
    "outputId": "9cdc90ff-41af-4240-f7c1-b574999d852e"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Q6dgLZ9kyqpO"
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import jsonlines\n",
    "import sys\n",
    "import time, os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_constant_schedule_with_warmup\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHhgkhaH-IUl"
   },
   "source": [
    "<a name=\"1\"></a>\n",
    "## **PART 1: Finetuning DistilBERT for NLI**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tD2YPuqeIYBN"
   },
   "source": [
    "### **What is the NLI task?ðŸ§**\n",
    "> Given a pair of sentences, denoted as a \"premise\" sentence and a \"hypothesis\" sentence, NLI (or RTE) aims to determine their logical relationship, i.e. whether they are logically follow (entailment), unfollow (contradiction) or are undetermined (neutral) to each other.\n",
    "\n",
    "> Defined as a machine learning task, NLI can be considered as a 3-classes (entailment, contradiction, or neutral) classification task, with a sentence-pair input (\"hypothesis\" and â€œpremiseâ€).\n",
    "\n",
    "> **You can run the following cell to have the first glance at your data**. Each data sample is a python dictionary, which consists of following components:\n",
    "- premise sentence (*'premise'*), \n",
    "- hypothesis sentence (*'hypothesis'*) \n",
    "- domain (*'domain'*): describing the topic of premise and hypothesis sentences (e.g., government regulations, telephone talks, etc.)\n",
    "- label (*'label'*): indicating the logical relation between premise and hypothesis (i.e., entailment, contradiction, or neutral)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 682,
     "status": "ok",
     "timestamp": 1680726359271,
     "user": {
      "displayName": "Prophecy Gaming PrG",
      "userId": "14056781264544618042"
     },
     "user_tz": -120
    },
    "id": "p-ODgcNUqYtm",
    "outputId": "963cc124-eac9-4b77-96b8-da7a8ff2ba40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'premise': 'The new rights are nice enough', 'hypothesis': 'Everyone really likes the newest benefits ', 'domain': 'slate', 'label': 'neutral'}\n",
      "{'premise': 'This site includes a list of all award winners and a searchable database of Government Executive articles.', 'hypothesis': 'The Government Executive articles housed on the website are not able to be searched.', 'domain': 'government', 'label': 'contradiction'}\n",
      "{'premise': \"uh i don't know i i have mixed emotions about him uh sometimes i like him but at the same times i love to see somebody beat him\", 'hypothesis': 'I like him for the most part, but would still enjoy seeing someone beat him.', 'domain': 'telephone', 'label': 'entailment'}\n"
     ]
    }
   ],
   "source": [
    "# If you use Google Colab, then data_dir = 'GOOGLE_DRIVE_PATH/nli_data'\n",
    "data_dir = ROOT_PATH+'/nli_data'\n",
    "data_dev_path = os.path.join(data_dir, 'dev_in_domain.jsonl')\n",
    "with jsonlines.open(data_dev_path, \"r\") as reader:\n",
    "    for sid, sample in enumerate(reader.iter()):\n",
    "        print(sample)\n",
    "        if sid == 2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 95,
     "status": "ok",
     "timestamp": 1680726359282,
     "user": {
      "displayName": "Prophecy Gaming PrG",
      "userId": "14056781264544618042"
     },
     "user_tz": -120
    },
    "id": "FF-dRWc7MZlL"
   },
   "outputs": [],
   "source": [
    "# Enter enter your Sciper number\n",
    "SCIPER = '283229'\n",
    "seed = int(SCIPER)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 95,
     "status": "ok",
     "timestamp": 1680726359289,
     "user": {
      "displayName": "Prophecy Gaming PrG",
      "userId": "14056781264544618042"
     },
     "user_tz": -120
    },
    "id": "9UPdzLSi4ZVt",
    "outputId": "1e9d9439-e8c7-4480-fb83-fee505e25c10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your random seed is:  283229\n"
     ]
    }
   ],
   "source": [
    "print('Your random seed is: ', seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252,
     "referenced_widgets": [
      "61f44c01830a453495fa23c33122ffbb",
      "a1ae95d1d72044dd954ac4ee0cd0b64d",
      "0d290adf55044765b04677404ee34408",
      "5b89f1fa3cf54b8eb3e9e5707b5d63f3",
      "4c2a86505c3a426394479d677f009493",
      "5915dd246fca4960a5e53f9639ea2892",
      "006a5e58dfd04454a12c9c3553e1a74a",
      "26fe01c5e2f84edea87320605a97b090",
      "3d7e9c589ec74e1a948948ccc51a443a",
      "499bf00fe9e84ce983468005f01fa226",
      "0ddc6de3b3c748bc89d1aeae1a9d8789",
      "95bfc4a3a197498e9858b5c4418d0c54",
      "90b24e100fde4cb0b2f1884878468a59",
      "2a10aba59c4a4b9f8b13718d40808ea9",
      "f412d59730dc486fb165e41ff04610de",
      "69db31922bfb483280f97b9e43b72943",
      "d4db477adc7142bda8bd5bde3785df00",
      "8b0f047c6116461cb3747d23c953a483",
      "b9fc7456171641d183303399ddb86b3d",
      "e94b9b7d472c41dba0d85df26d466a38",
      "ed1395f1c2f64f1d948e314bdfa4efcb",
      "b694aa8c38524f88bed1ad6adef91dfe",
      "fb1cb9be9f2d4794aa3f5a6ef64fc303",
      "607cdea2938c4b1b9f8106cb7de44661",
      "50a6c35c0cda4a96b35aa723708fc93d",
      "dec359686a06498697b1922c7ca75e2b",
      "0fea13c3d8f7445984143e42c3067ea2",
      "098e09c79c464eca88bb080e712f9bdc",
      "0a8a2757aa5845fd81a46d7e56afe34f",
      "823e4161906140c1b1f93429dc2ea6b0",
      "641afe3e9b404a0485b7b2afce92e643",
      "82458bca0c2a45deb1d233428c2b955d",
      "728d854d83964871b956bdb904311ce8",
      "c2347e18eb3d44fe9b20149d29c6021c",
      "6e2ab23538e4470bb69fb69e6d89f356",
      "d080fded4e234838b93b844cc0e8c1ee",
      "1cd29c3803774be6a8c802a991dbf3a2",
      "cf0ae0ae788c42dd8f8aa387410d6bcf",
      "475f7f3aeafe4820a5b2764953732603",
      "91d4740859cd48258e1d8f79d0bc4bfd",
      "92535a4bc32f4068bb39caad245750b6",
      "c6b58aa264474d97bad77ce4c3c20dc0",
      "61793d0782324c50a846e20157c6c384",
      "cf281efef9ee4a8599726cfa8127d73d"
     ]
    },
    "executionInfo": {
     "elapsed": 6006,
     "status": "ok",
     "timestamp": 1680726365219,
     "user": {
      "displayName": "Prophecy Gaming PrG",
      "userId": "14056781264544618042"
     },
     "user_tz": -120
    },
    "id": "GnX8VC4C0sHW",
    "outputId": "7dd4f194-73e0-4ee7-9303-3020e7325f9a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# We use the following pretrained tokenizer and model\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCETOFT2dB4u"
   },
   "source": [
    "### **1.1 Dataset Processing**\n",
    "Our first step is to load datasets for NLI task by constructing a Pytorch Dataset. Specifically, we will need to implement tokenization and padding with a HuggingFace pre-trained tokenizer.\n",
    "\n",
    "**Complete `NLIDataset` class following the instructions in `nli.py`, and test by running the following cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9085,
     "status": "ok",
     "timestamp": 1680726400575,
     "user": {
      "displayName": "Prophecy Gaming PrG",
      "userId": "14056781264544618042"
     },
     "user_tz": -120
    },
    "id": "_5Sya9W5BTDl",
    "outputId": "3ae157f4-7d8e-45c0-daf9-27f21edac67b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building NLI Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9815it [00:09, 1041.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from nli import NLIDataset\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "dataset = NLIDataset(ROOT_PATH+\"/nli_data/dev_in_domain.jsonl\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2619,
     "status": "ok",
     "timestamp": 1680685961135,
     "user": {
      "displayName": "Mathieu Desponds",
      "userId": "07341600198158272181"
     },
     "user_tz": -120
    },
    "id": "VFhuziVoEyG2",
    "outputId": "669ad3e2-bc79-4209-dd46-eb1f38e79d6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLIDataset test correct âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/desponds/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from testA2 import test_NLIDataset\n",
    "test_NLIDataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0weQpG6_3vO"
   },
   "source": [
    "### **1.2 Model Training and Evaluation**\n",
    "Next, we will implement the training and evaluation process to finetune the model. For model training, you will need to calculate the loss and update the model weights by update the optimizer. Additionally, we add a learning rate schedular to adopt an adaptive learning rate during the whole training process. \n",
    "\n",
    "For evaluation, you will need to compute accuracy and F1 scores to assess the model performance. \n",
    "\n",
    "**Complete the `compute_metric()`, `train()` and `evaluate()` functions following the instructions in the `nli.py` file, you can test compute_metric() by running the following cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1680727447565,
     "user": {
      "displayName": "Prophecy Gaming PrG",
      "userId": "14056781264544618042"
     },
     "user_tz": -120
    },
    "id": "6w7Leraw4tIY",
    "outputId": "a35b8e78-4d18-43c5-e886-b2e925405ce1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_metric test correct âœ…\n"
     ]
    }
   ],
   "source": [
    "from nli import compute_metrics, train, evaluate\n",
    "\n",
    "from testA2 import test_compute_metrics\n",
    "test_compute_metrics(compute_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pvCUS748_3vS"
   },
   "source": [
    "#### **Start Training and Validation!**\n",
    "\n",
    "Try the following different hyperparameter settings, compare and discuss the results. (Other hyperparameters should not be changed.)\n",
    "\n",
    "> A. learning_rate 2e-5\n",
    "\n",
    "> B. learning_rate 5e-5\n",
    "\n",
    "**Note:** *Each training will take about 1 hour using a GPU, please keep your computer and notebook active during the training.*\n",
    "\n",
    "**Questions: Which learning rate is better? Explain your answers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 106127,
     "status": "ok",
     "timestamp": 1680695360198,
     "user": {
      "displayName": "Prophecy Gaming PrG",
      "userId": "14056781264544618042"
     },
     "user_tz": -120
    },
    "id": "zn66mMOj_3vS",
    "outputId": "05591be0-46b6-4371-e693-928004383eac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building NLI Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "98176it [01:38, 999.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building NLI Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9815it [00:10, 980.48it/s]\n"
     ]
    }
   ],
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "model.to(device)\n",
    "\n",
    "train_dataset = NLIDataset(ROOT_PATH+\"/nli_data/train.jsonl\", tokenizer)\n",
    "dev_dataset = NLIDataset(ROOT_PATH+\"/nli_data/dev_in_domain.jsonl\", tokenizer)\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 4\n",
    "max_grad_norm = 1.0\n",
    "warmup_percent = 0.3\n",
    "model_save_root = ROOT_PATH+'/runs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3328184,
     "status": "ok",
     "timestamp": 1680689532211,
     "user": {
      "displayName": "Mathieu Desponds",
      "userId": "07341600198158272181"
     },
     "user_tz": -120
    },
    "id": "g07hvtGlshQU",
    "outputId": "adf6e747-68a7-4b09-8372-273e89a69320"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6136/6136 [13:35<00:00,  7.52it/s]\n",
      "Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 614/614 [00:23<00:00, 26.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Training Loss: 0.842 | Validation Loss: 0.660\n",
      "Epoch 0 NLI Validation:\n",
      "Accuracy: 72.83% | F1: (75.21%, 69.40%, 73.97%) | Macro-F1: 72.86%\n",
      "Model Saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6136/6136 [13:29<00:00,  7.58it/s]\n",
      "Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 614/614 [00:23<00:00, 25.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Training Loss: 0.567 | Validation Loss: 0.602\n",
      "Epoch 1 NLI Validation:\n",
      "Accuracy: 77.08% | F1: (79.58%, 73.21%, 78.25%) | Macro-F1: 77.01%\n",
      "Model Saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6136/6136 [13:31<00:00,  7.56it/s]\n",
      "Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 614/614 [00:23<00:00, 26.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Training Loss: 0.329 | Validation Loss: 0.633\n",
      "Epoch 2 NLI Validation:\n",
      "Accuracy: 76.70% | F1: (80.23%, 71.85%, 77.47%) | Macro-F1: 76.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6136/6136 [13:11<00:00,  7.75it/s]\n",
      "Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 614/614 [00:23<00:00, 26.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Training Loss: 0.182 | Validation Loss: 0.909\n",
      "Epoch 3 NLI Validation:\n",
      "Accuracy: 76.34% | F1: (80.15%, 71.26%, 76.96%) | Macro-F1: 76.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "learning_rate = 2e-5 # play around with this hyperparameter\n",
    "\n",
    "train(train_dataset, dev_dataset, model, device, batch_size, epochs,\n",
    "      learning_rate, warmup_percent, max_grad_norm, model_save_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z5aWqR1h_3vS",
    "outputId": "c07ac52a-f41c-4942-b076-bf74628d1607"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6136/6136 [13:48<00:00,  7.41it/s]\n",
      "Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 614/614 [00:24<00:00, 24.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Training Loss: 0.365 | Validation Loss: 0.785\n",
      "Epoch 0 NLI Validation:\n",
      "Accuracy: 74.53% | F1: (75.99%, 71.69%, 76.23%) | Macro-F1: 74.64%\n",
      "Model Saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6136/6136 [14:00<00:00,  7.30it/s]\n",
      "Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 614/614 [00:24<00:00, 24.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Training Loss: 0.371 | Validation Loss: 0.820\n",
      "Epoch 1 NLI Validation:\n",
      "Accuracy: 74.90% | F1: (78.53%, 69.15%, 76.25%) | Macro-F1: 74.64%\n",
      "Model Saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6136/6136 [13:41<00:00,  7.47it/s]\n",
      "Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 614/614 [00:24<00:00, 24.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Training Loss: 0.281 | Validation Loss: 0.703\n",
      "Epoch 2 NLI Validation:\n",
      "Accuracy: 74.81% | F1: (78.49%, 69.88%, 75.51%) | Macro-F1: 74.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6136/6136 [13:41<00:00,  7.47it/s]\n",
      "Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 614/614 [00:24<00:00, 24.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Training Loss: 0.212 | Validation Loss: 0.866\n",
      "Epoch 3 NLI Validation:\n",
      "Accuracy: 74.66% | F1: (78.35%, 69.33%, 75.64%) | Macro-F1: 74.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "learning_rate = 5e-5 # play around with this hyperparameter\n",
    "\n",
    "train(train_dataset, dev_dataset, model, device, batch_size, epochs,\n",
    "      learning_rate, warmup_percent, max_grad_norm, model_save_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QD-hn7PmW2hX"
   },
   "source": [
    "**Answer** : Based on the results of the two training sessions, it appears that using `learning_rate = 2e-5` yields superior outcomes compared to using `learning_rate = 5e-5`. The initial progress of the first model was comparatively slower and it reached its maximum later than the second model. On the other hand, the second model showed quicker progress in the beginning due to the higher learning rate, but ultimately failed to converge as the large learning step prevent its progress towards the maximum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGuzGJCB_3vT"
   },
   "source": [
    "### **Fine-Grained Validation**\n",
    "\n",
    "Use the model checkpoint saved under the first hyperparameter setting (learning_rate 2e-5) in 1.4, check the model performance on each domain subsets of the validation set, report the validation loss, accuracy, F1 scores and Macro-F1 on each domain, compare and discuss the results.\n",
    "\n",
    "**Questions: On which domain does the model perform the best? the worst? Give some possible explanations of why the model's best-performed domain is easier, and why the model's worst-performed domain is more challenging. Use some examples to support your explanations.**\n",
    "\n",
    "**Note:** To find examples for supporting your discussion, save the model prediction results on each domain under the './predictions/' folder, by specifying the *result_save_file* of the *evaluate* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 273,
     "status": "ok",
     "timestamp": 1680694390616,
     "user": {
      "displayName": "Prophecy Gaming PrG",
      "userId": "14056781264544618042"
     },
     "user_tz": -120
    },
    "id": "YCWWJjTP_3vT"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "learning_rate = 2e-5\n",
    "warmup_percent = 0.3\n",
    "checkpoint = ROOT_PATH+'/runs/lr{}-warmup{}'.format(learning_rate, warmup_percent)\n",
    "\n",
    "# Split the validation sets into subsets with different domains\n",
    "# Save the subsets under './nli_data/'\n",
    "# Replace \"...\" with your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pLyg_bIMEyG5"
   },
   "outputs": [],
   "source": [
    "data_by_domain = {}\n",
    "with jsonlines.open(data_dev_path, \"r\") as reader:\n",
    "    for sid, sample in enumerate(reader.iter()):\n",
    "        if sample['domain'] in data_by_domain :\n",
    "            data_by_domain[sample['domain']].append(sample)\n",
    "        else :\n",
    "            data_by_domain[sample['domain']] = [sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q4J2pu60xHTd",
    "outputId": "4ddc558c-43a5-4598-be78-08b545ecc421"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building NLI Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1973it [00:01, 1670.85it/s]\n",
      "Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 124/124 [00:03<00:00, 32.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain: fiction\n",
      "Validation Loss: 0.605 | Accuracy: 77.14%\n",
      "F1: (79.45%, 72.35%, 79.05%) | Macro-F1: 76.95%\n",
      "Building NLI Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1945it [00:03, 581.01it/s]\n",
      "Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 122/122 [00:05<00:00, 23.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain: government\n",
      "Validation Loss: 0.477 | Accuracy: 81.65%\n",
      "F1: (84.16%, 77.77%, 82.69%) | Macro-F1: 81.54%\n",
      "Building NLI Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1955it [00:01, 1213.58it/s]\n",
      "Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 123/123 [00:05<00:00, 24.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain: slate\n",
      "Validation Loss: 0.698 | Accuracy: 72.07%\n",
      "F1: (74.46%, 67.79%, 73.68%) | Macro-F1: 71.98%\n",
      "Building NLI Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1966it [00:02, 669.86it/s]\n",
      "Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 123/123 [00:06<00:00, 20.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain: telephone\n",
      "Validation Loss: 0.595 | Accuracy: 76.96%\n",
      "F1: (80.03%, 71.73%, 78.65%) | Macro-F1: 76.80%\n",
      "Building NLI Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1976it [00:01, 1106.10it/s]\n",
      "Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 124/124 [00:04<00:00, 25.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain: travel\n",
      "Validation Loss: 0.561 | Accuracy: 78.29%\n",
      "F1: (82.40%, 74.76%, 77.37%) | Macro-F1: 78.18%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(checkpoint)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(checkpoint)\n",
    "model.to(device)\n",
    "\n",
    "for domain in [\"fiction\", \"government\", \"slate\", \"telephone\", \"travel\"]:\n",
    "    \n",
    "    # Evaluate and save prediction results in each domain\n",
    "    # Replace \"...\" with your code\n",
    "    path = f\"{ROOT_PATH}/nli_data/domain_{domain}.jsonl\"\n",
    "    with jsonlines.open(path, mode='w') as writer:\n",
    "        for sample in data_by_domain[domain]:\n",
    "            writer.write(sample)\n",
    "    dev_domain_dataset = NLIDataset(path, tokenizer)\n",
    "    dev_loss, acc, f1_ent, f1_neu, f1_con = evaluate(\n",
    "        dev_domain_dataset, model, device, batch_size, no_labels=False, result_save_file= f\"{ROOT_PATH}/predictions/domain_{domain}.jsonl\")\n",
    "    macro_f1 = (f1_ent + f1_neu + f1_con) / 3\n",
    "    \n",
    "    print(f'Domain: {domain}')\n",
    "    print(f'Validation Loss: {dev_loss:.3f} | Accuracy: {acc*100:.2f}%')\n",
    "    print(f'F1: ({f1_ent*100:.2f}%, {f1_neu*100:.2f}%, {f1_con*100:.2f}%) | Macro-F1: {macro_f1*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***********************************\n",
      "Exemples of government\n",
      "\n",
      "    premise : GAO recommends that the Secretary of Defense revise policy and guidance,\n",
      "    hypothesis : GAO recommends that the Secretary of Defense revise policy and guidance\n",
      "\n",
      "    premise : Now suppose there is a private delivery firm in Cleveland that is competing with the postal service.,\n",
      "    hypothesis : Imagine a state-run delivery firm trying to phase out the postal service.\n",
      "\n",
      "    premise : The Commission's analysis uses both quantifiable and general descriptions of the effects of the rule on small entities.,\n",
      "    hypothesis : The rule has a significant effect on small entities.\n",
      "\n",
      "***********************************\n",
      "Exemples of slate\n",
      "\n",
      "    premise : Even the lower limit of that differential compounds to a hefty sum over time.,\n",
      "    hypothesis : The differential will not grow.\n",
      "\n",
      "    premise : Tom is the winner of a year's supply of Turtle Wax, and he will receive his prize just as soon as the Shopping Avenger figures out how much Turtle Wax actually constitutes a year's supply.,\n",
      "    hypothesis : There are no winners of the one year supply of Turtle wax.\n",
      "\n",
      "    premise : She gave the girl clothes and gifts and took her to her Connecticut estate for weekend pony rides, according to the Star . How was I supposed to compete with that?,\n",
      "    hypothesis : She gave the boy clothes, gifts and pony rides. That's hard to compete with.\n"
     ]
    }
   ],
   "source": [
    "save_repo_gvt = f\"{ROOT_PATH}/predictions/domain_government.jsonl\"\n",
    "save_repo_slate = f\"{ROOT_PATH}/predictions/domain_slate.jsonl\"\n",
    "predictions = []\n",
    "for i, repo in enumerate(zip([save_repo_gvt, save_repo_slate], ['government', 'slate'])):\n",
    "    with jsonlines.open(repo[0], \"r\") as reader:\n",
    "        print(f\"\\n***********************************\")\n",
    "        print(f\"Exemples of {repo[1]}\")\n",
    "        idx = np.random.randint(0,100, size = 3)\n",
    "        for i, sample in enumerate(reader.iter()):\n",
    "            if i in idx :\n",
    "                print(f\"\"\"\n",
    "    premise : {sample['premise']},\n",
    "    hypothesis : {sample['hypothesis']}\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6dmfllvoviX_"
   },
   "source": [
    "**Answer** : The domain where the model perform the best is `government` and where it perform the worst is `slate`.\n",
    "\n",
    "By looking deeper at the dataset and at the different domains, we can see that samples in the `government` domain are political or general declarative statment and are mostly not ambiguous. On the other side, `slate` domain is more ambiguous and labeling is harder on this domain. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6NyMZ5E4-QxM"
   },
   "source": [
    "## **Task2: Identify Shortcuts**\n",
    "\n",
    "We aim to find some shortcuts that the model in 1.4 (under the first hyperparameter setting) has learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4lCHLdaH_3vT"
   },
   "source": [
    "### **2.1 Word-Pair Pattern Extraction**\n",
    "\n",
    "We consider to exatrct simple word-pair patterns that the model may have learned from the NLI data. \n",
    "\n",
    "For this, we assume that a pair of words that occur in a premise-hypothesis sentence pair (one occurs in premise and the other occurs in hypothesis) may serve as a key indicator of the logical relationship between the premise and hypothesis sentences. For example:\n",
    "\n",
    ">- Premise: Consider the United States Postal Service.\n",
    ">- Hypothesis: Forget the United States Postal Service.\n",
    "\n",
    "Here the word-pair \"consider\" and \"forget\" determine that the premise and hypothesis have a *contradiction* relationship, so (consider, forget) --> *contradiction* might be a good pattern to learn.\n",
    "\n",
    "**Note:** \n",
    "- We do not consider the naive word pair patterns where the word from premise and the word from hypothesis are identical, e.g., (service, service) got from the above premise-hypothesis sentence pair.\n",
    "- We do not consider stop words neither, punctuations and words that contain special prefix '##', e.g., '##s' in the pattern extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1680694396765,
     "user": {
      "displayName": "Prophecy Gaming PrG",
      "userId": "14056781264544618042"
     },
     "user_tz": -120
    },
    "id": "7RKdt_-j_3vT",
    "outputId": "0e668377-0929-42cb-c341-b6fe83e74f61"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# stop_words and puntuations to be removed from consideration in the pattern extraction\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words.append('uh')\n",
    "\n",
    "import string\n",
    "puncs = string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NovYRxv_3vU"
   },
   "source": [
    "**Complete `word_pair_extraction()` function in `shortcut.py` file.**\n",
    "\n",
    "The keys of the returned dictionary *word_pairs* should be **different word-pairs** appered in premise-hypothesis sentence pairs, i.e., (a word from the premise, a word from the hypothesis).\n",
    "\n",
    "The value of a word-pair key records the counts of entailment, neutral and contradiction predictions **made by the model** when the word-pair occurs, i.e., \\[#entailment_predictions, #neutral_predictions,  #contradiction_predictions\\].\n",
    "\n",
    "**Note:** Remember to remove naive word pairs (i.e., premise word identical to hypothesis word), stop_words, puntuations and words with special prefix '##' out of consideration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTHt1frZ_3vU"
   },
   "source": [
    "### **2.2 Distill Potentially Useful Patterns**\n",
    "\n",
    "Find and print the **top-100** word-pairs that are associated with the **largest total number** of model predictions, which might contain frequently used patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1680694318791,
     "user": {
      "displayName": "Prophecy Gaming PrG",
      "userId": "14056781264544618042"
     },
     "user_tz": -120
    },
    "id": "IFZm6tFJFmlg"
   },
   "outputs": [],
   "source": [
    "from shortcut import word_pair_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8215,
     "status": "ok",
     "timestamp": 1680701101294,
     "user": {
      "displayName": "Prophecy Gaming PrG",
      "userId": "14056781264544618042"
     },
     "user_tz": -120
    },
    "id": "TUyal5mW_3vU",
    "outputId": "7a488200-106c-404b-9b44-8dd97b3c26a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('know', 'i'): [28, 36, 23], ('don', 'i'): [27, 22, 24], ('like', 'i'): [16, 18, 12], ('services', 'legal'): [19, 12, 15], ('know', 'don'): [14, 15, 15], ('legal', 'services'): [16, 8, 15], ('yeah', 'i'): [11, 15, 10], ('im', 'i'): [16, 12, 6], ('time', 'i'): [15, 10, 7], ('service', 'postal'): [12, 9, 11], ('go', 'i'): [15, 7, 9], ('would', 'i'): [7, 18, 5], ('one', 'i'): [11, 9, 10], ('really', 'i'): [11, 11, 8], ('think', 'i'): [14, 9, 6], ('know', 'lot'): [8, 19, 2], ('postal', 'service'): [10, 9, 9], ('that', 'i'): [10, 9, 9], ('know', 'make'): [4, 13, 11], ('would', 'could'): [7, 14, 5], ('got', 'i'): [13, 6, 7], ('like', 'don'): [5, 5, 16], ('get', 'i'): [9, 7, 9], ('test', 'toxicity'): [8, 8, 8], ('iv', 'i'): [10, 9, 5], ('um', 'i'): [6, 14, 4], ('like', 'think'): [14, 8, 1], ('know', 'never'): [0, 0, 23], ('know', 'time'): [3, 14, 5], ('see', 'i'): [7, 6, 8], ('could', 'would'): [6, 13, 2], ('ill', 'i'): [10, 1, 9], ('try', 'would'): [7, 1, 12], ('last', 'years'): [11, 5, 4], ('like', 'never'): [3, 1, 16], ('know', 'like'): [13, 7, 0], ('know', 'get'): [5, 8, 7], ('like', 'lot'): [11, 7, 1], ('think', 'would'): [3, 11, 5], ('would', 'people'): [4, 11, 4], ('know', 'people'): [8, 8, 3], ('they', 'get'): [4, 10, 5], ('mail', 'postal'): [6, 5, 8], ('know', 'money'): [9, 7, 3], ('lot', 'would'): [7, 5, 7], ('really', 'would'): [6, 4, 8], ('one', 'people'): [9, 7, 2], ('first', 'mail'): [3, 6, 9], ('year', 'last'): [7, 3, 8], ('may', 'might'): [12, 4, 2], ('good', 'i'): [7, 2, 9], ('know', 'try'): [8, 2, 8], ('out', 'would'): [6, 0, 12], ('one', 'get'): [5, 8, 4], ('going', 'get'): [7, 7, 3], ('don', 'like'): [12, 2, 3], ('york', 'new'): [7, 6, 4], ('know', 'take'): [4, 8, 5], ('even', 'i'): [7, 4, 6], ('know', 'would'): [1, 12, 4], ('know', 'think'): [5, 1, 11], ('know', 'go'): [3, 3, 11], ('kind', 'i'): [3, 8, 6], ('he', 'would'): [5, 3, 8], ('many', 'people'): [10, 3, 3], ('i', 'don'): [4, 5, 7], ('would', 'don'): [4, 7, 5], ('like', 'could'): [5, 9, 2], ('policies', 'life'): [6, 4, 6], ('technology', 'information'): [7, 4, 5], ('costs', 'cost'): [8, 4, 4], ('years', 'i'): [6, 6, 4], ('last', 'i'): [4, 7, 5], ('never', 'i'): [8, 4, 4], ('right', 'i'): [7, 3, 6], ('know', 'could'): [5, 6, 5], ('went', 'i'): [6, 8, 2], ('old', 'i'): [4, 9, 2], ('know', 'long'): [5, 8, 2], ('i', 'think'): [5, 7, 3], ('i', 'didn'): [6, 4, 5], ('don', 'think'): [4, 3, 8], ('day', 'i'): [2, 5, 8], ('two', 'one'): [4, 3, 8], ('know', 'making'): [4, 2, 9], ('time', 'would'): [5, 2, 8], ('first', 'i'): [6, 3, 6], ('well', 'get'): [4, 6, 5], ('president', 'vice'): [1, 9, 5], ('gao', 'vice'): [2, 8, 5], ('people', 'would'): [3, 8, 4], ('legal', 'aid'): [7, 4, 4], ('legal', 'state'): [5, 1, 9], ('state', 'legal'): [6, 3, 6], ('information', 'state'): [15, 0, 0], ('like', 'tax'): [6, 4, 5], ('money', 'loan'): [5, 10, 0], ('money', 'lot'): [5, 10, 0], ('know', 'really'): [2, 5, 8], ('going', 'i'): [5, 4, 6]}\n"
     ]
    }
   ],
   "source": [
    "# all your saved model prediction results in 1.2 Fine-Grained Validation\n",
    "domains = [\"fiction\", \"government\", \"slate\", \"telephone\", \"travel\"]\n",
    "prediction_files = [f\"{ROOT_PATH}/nli_data/val_by_domains/domain_{domain}.jsonl\" for domain in domains]\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(checkpoint)\n",
    "word_pairs = word_pair_extraction(prediction_files, tokenizer)\n",
    "\n",
    "# find top-100 word-pairs associated with the largest total number of model predictions\n",
    "top_100_freq_pairs = dict(sorted(word_pairs.items(), key=lambda item: -sum(item[1]))[:100])\n",
    "\n",
    "print(top_100_freq_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pz25EvuI_3vU"
   },
   "source": [
    "**Among the top-100 frequent word-pairs above**, find out the **top-5** word-pairs whose occurances **most likely** lead to *entailment* predictions (entailment patterns), and the **top-5** word-pairs whose occurances **most likely** lead to *contradiction* predictions (contradiction patterns).\n",
    "\n",
    "**Explain your rules for finding these word pairs.**\n",
    "\n",
    "Explanation of the rule to find the word-pair whose occurances **most likely** lead to *entailment*:\n",
    "\n",
    "We want to maximize the probability that a pair of words gives  *entailment*. This can we written as maximizing $ C_e / (C_e + C_n + C_c)$ where $C_e, C_n, C_c$ is the number of times the word pair appears in  *entailment*, *neutral* and  *contradiction* respectively. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 268,
     "status": "ok",
     "timestamp": 1680694460924,
     "user": {
      "displayName": "Prophecy Gaming PrG",
      "userId": "14056781264544618042"
     },
     "user_tz": -120
    },
    "id": "Yq2cVOaWTEYw",
    "outputId": "038d53b2-2106-497d-9802-8c461b7702e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entailment Patterns:\n",
      "{('information', 'state'): [15, 0, 0], ('don', 'like'): [12, 2, 3], ('may', 'might'): [12, 4, 2], ('know', 'like'): [13, 7, 0], ('many', 'people'): [10, 3, 3]}\n",
      "Contradiction Patterns:\n",
      "{('know', 'never'): [0, 0, 23], ('like', 'never'): [3, 1, 16], ('out', 'would'): [6, 0, 12], ('know', 'think'): [5, 1, 11], ('know', 'go'): [3, 3, 11]}\n"
     ]
    }
   ],
   "source": [
    "# find top-5 entailment and contradiction patterns\n",
    "top_5_entailment = dict(sorted(top_100_freq_pairs.items(), key=lambda item: -item[1][0] / sum([i for i in item[1]]))[:5])\n",
    "top_5_contradict = dict(sorted(top_100_freq_pairs.items(), key=lambda item: -item[1][2] / sum([i for i in item[1]]))[:5])\n",
    "\n",
    "print(\"Entailment Patterns:\")\n",
    "print(top_5_entailment)\n",
    "print(\"Contradiction Patterns:\")\n",
    "print(top_5_contradict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjVti-vL_3vV"
   },
   "source": [
    "### **2.3 Case Study**\n",
    "\n",
    "Find out and study **4 representative** cases where the pattern that you have found in 2.2 **fails**, e.g., the premise-hypothesis sentence pair contains ('good', 'bad'), but has an *entailment* gold label.\n",
    "\n",
    "**Based on your case study, explain the limitations of the word-pair patterns.**\n",
    "\n",
    "**Answer** : \n",
    "To begin with, based on the previous point, it is evident that the frequent occurrence of certain word pairs in a particular context does not necessarily hold significant meaning for humans. It is unexpected that the words \"know\" and \"never\" only appear in *conradiction* to each other, indicating a certain degree of limitation of word-pair patterns.\n",
    "\n",
    "Furthermore, the case study demonstrates that although the words \"like\" and \"never\" appear in the premise and hypothesis respectively, the sentences are lengthy and do not exhibit a direct contradiction between the two words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1680701119799,
     "user": {
      "displayName": "Prophecy Gaming PrG",
      "userId": "14056781264544618042"
     },
     "user_tz": -120
    },
    "id": "2XyPmb01_3vV",
    "outputId": "aab725c7-b6f3-4f0d-ee87-adc336118cf3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'premise': 'I\\'m not sentimental, you know.\" She paused.',\n",
       "  'hypothesis': \"Everyone thinks she's sentimental. \",\n",
       "  'domain': 'fiction',\n",
       "  'label': 'neutral'},\n",
       " {'premise': \"And, although I got a Ph.D. in philosophy many years ago and have thought and read about these matters ever since, heaven (or whatever) knows I don't have too many answers that I feel confident about.\",\n",
       "  'hypothesis': \"I have been thinking about this since I earned my degree, but I still don't know for sure.\",\n",
       "  'domain': 'slate',\n",
       "  'label': 'entailment'},\n",
       " {'premise': 'you sound like this girl that i talked to about books and we got into movies one night',\n",
       "  'hypothesis': 'I found out about so many movies I had never heard of.',\n",
       "  'domain': 'telephone',\n",
       "  'label': 'neutral'},\n",
       " {'premise': \"because i i mean i don't know it's just something i think something we need\",\n",
       "  'hypothesis': 'I think it is something that we need.',\n",
       "  'domain': 'telephone',\n",
       "  'label': 'entailment'}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "representatives = []\n",
    "study_cases = [('like', 'never'), ('know', 'think')]\n",
    "for pred_file in prediction_files:\n",
    "    with jsonlines.open(pred_file, \"r\") as reader:\n",
    "        for sample in reader.iter():\n",
    "            for study_case in study_cases :\n",
    "                if study_case[0] in sample['premise'] and \\\n",
    "                    study_case[1] in sample['hypothesis'] and \\\n",
    "                    sample['label'] != 'contradiction' :\n",
    "                    representatives.append(sample)\n",
    "representatives[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yND0DEfT-eXn"
   },
   "source": [
    "## **Task3: Annotate New Data**\n",
    "\n",
    "To check the robustness of developed model, **some additional sets of test data** are collected (under /nli_data/test_data/), which contain NLI samples that are out of the domains of the training and validation data.\n",
    "\n",
    "However, the test data does not have gold labels of the relationships between premise and hypothesis sentences, i.e., all the labels are marked as *hidden*. **We consider to annotate the data by ourselves.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQNXrRHr_3vV"
   },
   "source": [
    "### **3.1 Write an Annotation Guideline**\n",
    "\n",
    "Imagine that you are going to assign this annotation task to a crowdsourcing worker, who is completely not familiar with computer science and NLP. Think about how you are going to explain this annotation task to him in order to guide him do a decent job. Write an annotation guideline for such a worker who are going to do this task for you.\n",
    "\n",
    "**Note:** You should come up with your own guideline without the help of your partner(s) in later Task 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfkqNbUA_3vV"
   },
   "source": [
    "Annotation guideline: \n",
    "\n",
    "**In general** :\n",
    "- Avoid making assumptions or drawing inferences beyond what is explicitly stated in the *premise* and *hypothesis*.\n",
    "\n",
    "**Both of the sentences are questions** :\n",
    "- Classify the sample as *entailment* if the *hypothesis* is a restatement or a paraphrase of the *premise* that preserves the meaning of the original statement.\n",
    "- Classify the sample as *contradiction* if the *hypothesis* is asking the contrary of the *premise*, i.e., if it contradicts the information presented in the *premise*.\n",
    "- Classify the sample as neutral if there is no clear link between the *premise* and the *hypothesis* or if the *hypothesis* is unrelated to the *premise*.\n",
    "\n",
    "**Both of the sentences are NOT questions** :\n",
    "- Classify the sample as *entailment* if the *hypothesis* can be said to be true only by knowing the *premise*.\n",
    "- Classify the sample as *contradiction* if the *hypothesis* can be said to be wrong only by knowing the *premise*, or if there is a clear contradiction between the two sentence. e.g. \"A cat is on the fridge\", \"A cat is on the sofa\".\n",
    "- Classify the sample as *neutral* if we can not say if the *hypothesis* is true or false only knowing the *premise*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBWK4Bw__3vV"
   },
   "source": [
    "### **3.2 Annotate Your 100 Datapoints with Partner(s)**\n",
    "\n",
    "Annotate your 100 test datapoints with your partner(s), by editing the value of the key \"label_student1\", \"label_student2\" and \"label_student3\" (if you are in a group of three students) in each datapoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cczFQm0eHknv"
   },
   "source": [
    "**Note:** \n",
    "- You can download the assigned annotation file (`<your-testset-id>.jsonl`) by [this link](https://drive.google.com/drive/folders/146ExExmpnSUayu6ArGiN5gQzCPJp0myB?usp=share_link)\n",
    "- Please find your annotation partner according to the \"Student Pairing List for A2 Task3\" shared on Ed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWhjTn2fQ5YE"
   },
   "source": [
    "**Name your annotated file as `<index>-<sciper_number>.jsonl`.** \n",
    "\n",
    "For example, if you get `01.jsonl` to annotate, you should name your deliverable as `01-<your_sciper_number>.jsonl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rnsUj2uZEyHD"
   },
   "outputs": [],
   "source": [
    "# Read the json file \n",
    "text_samples = []\n",
    "with jsonlines.open(data_dir+\"/12.jsonl\", \"r\") as reader:\n",
    "    for sample in reader.iter():\n",
    "        text_samples.append(sample)\n",
    "\n",
    "# Read the text file where my labels are written and write them in text_samples\n",
    "labels = []\n",
    "with open(data_dir+\"/labels.txt\") as reader :\n",
    "    labels = [line[0] for line in reader.readlines()]\n",
    "    \n",
    "for i, lab in enumerate(labels) :\n",
    "    if lab == 'E':\n",
    "        labels[i] = 'entailment'\n",
    "    elif lab == 'N' :\n",
    "        labels[i] = 'neutral'\n",
    "    if lab == 'C':\n",
    "        labels[i] = 'contradiction'\n",
    "        \n",
    "for i, text in enumerate(text_samples):\n",
    "    text_samples[i].update({'label_student2': labels[i]})\n",
    "\n",
    "# Write the jsonl file with my labels\n",
    "with jsonlines.open(data_dir+'/12-283229.jsonl', mode='w') as writer:\n",
    "    for text in text_samples:\n",
    "        writer.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uyP0GtHe_3vW"
   },
   "source": [
    "### **3.3 Agreement Measure**\n",
    "\n",
    "Based on your and your partner's annotations on the 100 test datapoints in 3.2, calculate the [Cohen's Kappa](https://scikit-learn.org/stable/modules/model_evaluation.html#cohen-kappa) or [Krippendorff's Alpha](https://github.com/pln-fing-udelar/fast-krippendorff) (if you are in a group of three students) between the annotators. Discuss the agreement measure results.\n",
    "\n",
    "**Note:** Cohen's Kappa or Krippendorff's Alpha interpretation\n",
    "\n",
    "0: No Agreement\n",
    "\n",
    "0 ~ 0.2: Slight Agreement\n",
    "\n",
    "0.2 ~ 0.4: Fair Agreement\n",
    "\n",
    "0.4 ~ 0.6: Moderate Agreement\n",
    "\n",
    "0.6 ~ 0.8: Substantial Agreement\n",
    "\n",
    "0.8 ~ 1.0: Near Perfect Agreement\n",
    "\n",
    "1.0: Perfect Agreement\n",
    "\n",
    "> **Questions**: What is your interpretation of Cohen's Kappa or Krippendorff's Alpha value according to the above mapping? Which kind of disagreements are most frequently happen between you and your partner(s), i.e., *entailment* vs. *neutral*, *entailment* vs. *contradiction*, or *neutral* vs. *contradiction*? For the second question, give some examples to explain why that is the case. Are there possible ways to address the disagrrements between two annotators?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "565ia289EyHF",
    "outputId": "4c53eed6-fa74-43f8-dfae-9193ab92ebba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over the 24 disagreement,\n",
      "12 are between entailement and neutral (5,7) \n",
      "9 are between entailement and contradiction (4,5), \n",
      "3 are between neutral and contradiction (2,1)\n",
      "where the parenthesis mean for the first line that :\n",
      "   (I choose entailment and he said neutral, I choose neutral and he said entailment)\n"
     ]
    }
   ],
   "source": [
    "# Read the labels of my teammate\n",
    "with jsonlines.open(data_dir+\"/david.jsonl\", \"r\") as reader:\n",
    "    for i,sample in enumerate(reader.iter()):\n",
    "        text_samples[i].update({'label_student1': sample['label_student1']})\n",
    "\n",
    "# Compute the Cohan Kappa Score and the accuracy between us \n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "my_label = [text['label_student2'] for text in text_samples]\n",
    "his_label = [text['label_student1'] for text in text_samples]\n",
    "accuracy = sum([1 for i in range(len(my_label)) if my_label[i] ==his_label[i]])/len(my_label)\n",
    "print(f\"The Cohen's Kappa Alpha value is {cohen_kappa_score(my_label, his_label)} which according to the above mapping means a Substantial Agreement.\")\n",
    "print(f\"The percentage of aggreament is {accuracy}%\")\n",
    "\n",
    "# Get insight about our disagreements \n",
    "e_vs_n = sum([1 for i in range(len(my_label)) if (my_label[i] == \"entailment\" and his_label[i] == \"neutral\")])\n",
    "n_vs_e = sum([1 for i in range(len(my_label)) if (my_label[i] == \"neutral\" and his_label[i] == \"entailment\")])\n",
    "e_vs_c = sum([1 for i in range(len(my_label)) if (my_label[i] == \"entailment\" and his_label[i] == \"contradiction\")])\n",
    "c_vs_e = sum([1 for i in range(len(my_label)) if (my_label[i] == \"contradiction\" and his_label[i] == \"entailment\")])\n",
    "c_vs_n = sum([1 for i in range(len(my_label)) if (my_label[i] == \"neutral\" and his_label[i] == \"contradiction\")])\n",
    "n_vs_c = sum([1 for i in range(len(my_label)) if (my_label[i] == \"contradiction\" and his_label[i] == \"neutral\")])\n",
    "print(f\"\"\"Over the {int(100- accuracy*100)} disagreement,\n",
    "{e_vs_n+n_vs_e} are between entailement and neutral ({e_vs_n},{n_vs_e}) \n",
    "{e_vs_c+c_vs_e} are between entailement and contradiction ({e_vs_c},{c_vs_e}), \n",
    "{c_vs_n+n_vs_c} are between neutral and contradiction ({c_vs_n},{n_vs_c})\n",
    "where the parenthesis mean for the first line that :\n",
    "   (I choose entailment and he said neutral, I choose neutral and he said entailment)\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMxezT5WEyHG"
   },
   "source": [
    "**Answer** : The Cohen's Kappa Alpha value is $0.627$ which according to the above mapping means a Substantial Agreement.\n",
    "\n",
    "An analysis of the labeled data revealed that the most frequent types of disagreements were between *entailment* and *neutral*, followed closely by *entailment* and *contradiction*. These types of disagreements are unlikely to result from discrepancies in the labeling guidelines, as they occur in both directions. However, upon closer examination of the samples where disagreements occurred between *entailment* and *neutral*, we observed that it was often difficult to determine whether the information in the hypothesis was newly introduced or could be deduced from the premise. In cases where disagreements occurred between *entailment* and *contradiction*, we found that the premises were often lengthy and contained a significant amount of information, making it challenging to identify the exact location of the contradiction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ff12-RLf_3vW"
   },
   "source": [
    "### **3.4 Robustness Check**\n",
    "\n",
    "Take into account both your and your partner's annotations, determine the final labels of the 100 test datapoints, by editing the value of the key \"label\" in each of your datapoint.\n",
    "\n",
    "Evaluate the performance of your developed model in 1.4 (still under the first hyperparameter setting) on your annotated 100 test datapoints, and compare with the model performance on the validation set.\n",
    "\n",
    "> **Question**: Do you think that your developed model has a good robuestness of handling out-of-domain NLI predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LowJ05h6ypaA",
    "outputId": "006332f6-59d7-4328-b896-943ea260d8da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building NLI Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 249.22it/s]\n",
      "Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 27.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain: travel\n",
      "Validation Loss: 0.915 | Accuracy: 65.00%\n",
      "F1: (72.09%, 51.06%, 65.67%) | Macro-F1: 62.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = f\"{ROOT_PATH}/nli_data/12-final.jsonl\"\n",
    "labeled_dataset = NLIDataset(path, tokenizer)\n",
    "labeled_loss, acc, f1_ent, f1_neu, f1_con = evaluate(\n",
    "    labeled_dataset, model, device, batch_size, no_labels=False, result_save_file= f\"{ROOT_PATH}/predictions/labeled_validation.jsonl\")\n",
    "macro_f1 = (f1_ent + f1_neu + f1_con) / 3\n",
    "print()\n",
    "print(f'Validation Loss: {labeled_loss:.3f} | Accuracy: {acc*100:.2f}%')\n",
    "print(f'F1: ({f1_ent*100:.2f}%, {f1_neu*100:.2f}%, {f1_con*100:.2f}%) | Macro-F1: {macro_f1*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5ha7cTr1HRs"
   },
   "source": [
    "**Answer** : With the out-domain NLI dataset, we see that the accuracy and the Macro-F1 drop significantly compared to what we saw in point 1.2. \n",
    "\n",
    "Our NLP model's performance degradation on out-of-domain samples highlights the fact that we trained only on a small dataset and the importance of diversifying the training data and incorporating a wider range of samples to enhance its generalization capability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4wuRpHt-rQF"
   },
   "source": [
    "## **Task4: Data Augmentation**\n",
    "\n",
    "Finally, we consider to use a data augmentation method to create more training data, and use the augmented data to improve the model performance. The data augmentation method we are going to use is [EDA](https://aclanthology.org/D19-1670/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEtgwKJt0kfO"
   },
   "source": [
    "### **4.1 EDA: Easy Data Augmentation algorithm for Text**\n",
    "\n",
    "For this section, we will need to implement the most simple data augmentation techniques on textual sentences, including **SR** (Synonym Replacement), **RD** (Random Deletion), **RS** (Random Swap), **RI** (Random Insertion). \n",
    "\n",
    "You should complete all the functions in `eda.py` script, and you can test them with a simple testcase by running the following cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djFbjk31AR0M"
   },
   "source": [
    "- **Synonym Replacement (SR)**\n",
    "> In Synonym Replacement, we randomly replace some words in the sentence with their synonyms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G2ZExbEb03IN",
    "outputId": "e330e5e6-dd72-47fe-e8c5-f25faada9779"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mathi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mathi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "  \n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZyJi-zYyIqsq"
   },
   "source": [
    "You can test whether you get the synonyms right and see an example with synonym replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZMRmcZtx81R4",
    "outputId": "18db025f-24a9-4193-b021-94aabb01f717"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The synonyms for the word \"task\" are:  ['job', 'undertaking', 'tax', 'labor', 'project', 'chore']\n"
     ]
    }
   ],
   "source": [
    "from eda import get_synonyms\n",
    "from testA2 import test_get_synonyms\n",
    "\n",
    "test_get_synonyms(get_synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AjFGy4DLFziY",
    "outputId": "f59c9e38-419e-4eaf-cab9-7f422512eea2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Example of Synonym Replacement: hey humanity how are you doing\n"
     ]
    }
   ],
   "source": [
    "from eda import synonym_replacement\n",
    "\n",
    "print(f\" Example of Synonym Replacement: {synonym_replacement('hey man how are you doing',3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfdHwyxaJXUn"
   },
   "source": [
    "- **Random Deletion (RD)**\n",
    "\n",
    "> In Random Deletion, we randomly delete a word if a uniformly generated number between 0 and 1 is smaller than a pre-defined threshold. This allows for a random deletion of some words of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "76bVm640Msa7",
    "outputId": "8b5513c6-8c52-4013-a614-38d218a0358a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Example of Random Deletion: hey how are you doing\n"
     ]
    }
   ],
   "source": [
    "from eda import random_deletion\n",
    "\n",
    "print(f\" Example of Random Deletion: {random_deletion('hey man how are you doing', p=0.3, max_deletion_n=3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ajqx9cABNk5a"
   },
   "source": [
    "- **Random Swap (RS)**\n",
    "> In Random Swap, we randomly swap the order of two words in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Vuott-vQn6W",
    "outputId": "9d2efb7e-3ea3-43e6-9b1a-95ff24983ec6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Example of Random Swap: hey man how are doing you\n"
     ]
    }
   ],
   "source": [
    "from eda import swap_word\n",
    "\n",
    "print(f\" Example of Random Swap: {swap_word('hey man how are you doing')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSpcGqdfQ78_"
   },
   "source": [
    "- **Random Insertion (RI)**\n",
    "> Finally, in Random Insertion, we randomly insert synonyms of a word at a random position.\n",
    "> Data augmentation operations should not change the true label of a sentence, as that would introduce unnecessary noise into the data. Inserting a synonym of a word in a sentence, opposed to a random word, is more likely to be relevant to the context and retain the original label of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G5itS2lJRmvV",
    "outputId": "eca3f98e-6aed-4d63-c281-c450a0b8aa01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Example of Random Insertion: hey man how are isle of man you human being doing\n"
     ]
    }
   ],
   "source": [
    "from eda import random_insertion\n",
    "\n",
    "print(f\" Example of Random Insertion: {random_insertion('hey man how are you doing', n=2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGOlMl3n1SyJ"
   },
   "source": [
    "### **4.2 Augment Your Model**\n",
    "\n",
    "Combine all the functions you have implemented in 4.1, you can come up with your own data augmentation pipeline with various p and n ;)\n",
    "\n",
    "Next step is to expand the training data you used in Task1, re-train your model in 1.4 on your augmented data, and re-evaluate its performance on both the given validation set as well as on your manually annotated 100 test datapoints. \n",
    "\n",
    "Discuss the improvements that your data augmentation brings to your model. ***Include some examples of old vs. new model predictions to demonstrate the improvements.***\n",
    "\n",
    "**Warning: In terms of data size and training time control, we stipulate that your augmented training data should not be larger than 100M.** (Currently the training data train.jsonl is about 25M.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d0pTcUsYzsGZ",
    "outputId": "437a379c-faf6-401f-a270-296f70704d1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original Sentence : hey man how are you doing\n",
      " SR Augmented Sentence : hey mankind how are you doing\n",
      " RD Augmented Sentence : hey man how you doing\n",
      " RS Augmented Sentence : you man how are hey doing\n",
      " RI Augmented Sentence : hey military personnel world man how are you doing\n"
     ]
    }
   ],
   "source": [
    "def aug(sent,n,p):\n",
    "    print(f\" Original Sentence : {sent}\")\n",
    "    print(f\" SR Augmented Sentence : {synonym_replacement(sent, n)}\")\n",
    "    print(f\" RD Augmented Sentence : {random_deletion(sent, p, n)}\")\n",
    "    print(f\" RS Augmented Sentence : {swap_word(sent)}\")\n",
    "    print(f\" RI Augmented Sentence : {random_insertion(sent,n)}\")\n",
    "    \n",
    "aug('hey man how are you doing', p=0.2, n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-0U-CD323iY"
   },
   "source": [
    "- Augment training dataset and Re-train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uExoah4O1ZCC"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "p = 0.3\n",
    "n = 3\n",
    "def aug_sent(sent,p):\n",
    "    out = [sent]\n",
    "    not_used = random.randint(0,3) if len(sent.split()) > 1 else 2\n",
    "    if not_used != 0 :\n",
    "        out.append(synonym_replacement(sent, n))\n",
    "    if not_used != 1 :\n",
    "        out.append(random_deletion(sent, p, n))\n",
    "    if not_used != 2 :\n",
    "        out.append(swap_word(sent))\n",
    "    if not_used != 3 :\n",
    "        out.append(random_insertion(sent,n))\n",
    "    return out\n",
    "\n",
    "def aug_sample(sample):\n",
    "    out = []\n",
    "    aug_pre = aug_sent(sample['premise'],p)\n",
    "    aug_hyp = aug_sent(sample['hypothesis'],p)\n",
    "    random.shuffle(aug_hyp)\n",
    "    for i in range(len(aug_pre)):\n",
    "        out.append(\n",
    "        {\n",
    "            'premise' : aug_pre[i],\n",
    "            'hypthesis' : aug_hyp[i],\n",
    "            'label' : sample['label']\n",
    "        })\n",
    "    return out\n",
    "\n",
    "def aug_data(data_repo):\n",
    "    final = []\n",
    "    with jsonlines.open(data_repo, \"r\") as reader:\n",
    "            for sample in tqdm(reader.iter()):\n",
    "                final.extend(aug_sample(sample))\n",
    "    return final\n",
    "aug_sent('hey man how are you doing', p=0.3)\n",
    "augmented_data = aug_data(ROOT_PATH+\"/nli_data/train.jsonl\")\n",
    "\n",
    "with jsonlines.open(ROOT_PATH+\"/nli_data/augmented_train.jsonl\", mode='w') as writer:\n",
    "    for sample in augmented_data:\n",
    "        writer.write(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 447610,
     "status": "ok",
     "timestamp": 1680726856949,
     "user": {
      "displayName": "Prophecy Gaming PrG",
      "userId": "14056781264544618042"
     },
     "user_tz": -120
    },
    "id": "aOOYhpre6__t",
    "outputId": "fb61ce79-ffdd-4911-df95-4f2462fb4a08"
   },
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "model.to(device)\n",
    "\n",
    "train_dataset = NLIDataset(ROOT_PATH+\"/nli_data/augmented_train.jsonl\", tokenizer)\n",
    "dev_dataset = NLIDataset(ROOT_PATH+\"/nli_data/dev_in_domain.jsonl\", tokenizer)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 4\n",
    "max_grad_norm = 1.0\n",
    "warmup_percent = 0.3\n",
    "model_save_root = ROOT_PATH+'/runs/augmented/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bwOC3weANU-c",
    "outputId": "cdd2019d-c0ee-4c7a-cce4-aa451fe69c59"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12272/12272 [30:16<00:00,  6.76it/s]\n",
      "Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [00:14<00:00, 21.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Training Loss: 0.222 | Validation Loss: 0.901\n",
      "Epoch 0 NLI Validation:\n",
      "Accuracy: 76.88% | F1: (79.78%, 72.13%, 78.39%) | Macro-F1: 76.77%\n",
      "Model Saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12272/12272 [30:00<00:00,  6.81it/s]\n",
      "Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [00:14<00:00, 21.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Training Loss: 0.095 | Validation Loss: 1.252\n",
      "Epoch 1 NLI Validation:\n",
      "Accuracy: 75.94% | F1: (79.33%, 70.54%, 77.34%) | Macro-F1: 75.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12272/12272 [29:58<00:00,  6.82it/s]\n",
      "Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [00:14<00:00, 21.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Training Loss: 0.042 | Validation Loss: 1.678\n",
      "Epoch 2 NLI Validation:\n",
      "Accuracy: 76.07% | F1: (79.38%, 71.33%, 77.23%) | Macro-F1: 75.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12272/12272 [29:56<00:00,  6.83it/s]\n",
      "Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [00:14<00:00, 21.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Training Loss: 0.027 | Validation Loss: 1.854\n",
      "Epoch 3 NLI Validation:\n",
      "Accuracy: 76.04% | F1: (79.20%, 71.25%, 77.31%) | Macro-F1: 75.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 8e-6\n",
    "\n",
    "train(train_dataset, dev_dataset, model, device, batch_size, epochs,\n",
    "      learning_rate, warmup_percent, max_grad_norm, model_save_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_WmsHhOChLYW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 307/307 [00:14<00:00, 21.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Dataset\n",
      "Validation Loss: 0.901 | Accuracy: 76.88%\n",
      "F1: (79.78%, 72.13%, 78.39%) | Macro-F1: 76.77%\n",
      "Building NLI Dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 1068.70it/s]\n",
      "Evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 30.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled dataset\n",
      "Validation Loss: 1.291 | Accuracy: 66.00%\n",
      "F1: (75.29%, 54.17%, 62.69%) | Macro-F1: 64.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the resulted with the new model for each of the domains\n",
    "checkpoint = ROOT_PATH+'/runs/augmented/lr{}-warmup{}'.format(learning_rate, warmup_percent)\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(checkpoint)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(checkpoint)\n",
    "model.to(device)\n",
    "\n",
    "dev_loss, acc, f1_ent, f1_neu, f1_con = evaluate(\n",
    "    dev_dataset, model, device, batch_size, no_labels=False, result_save_file= f\"{ROOT_PATH}/predictions/augmented/validation_dataset.jsonl\")\n",
    "macro_f1 = (f1_ent + f1_neu + f1_con) / 3\n",
    "\n",
    "print(f'Validation Dataset')\n",
    "print(f'Validation Loss: {dev_loss:.3f} | Accuracy: {acc*100:.2f}%')\n",
    "print(f'F1: ({f1_ent*100:.2f}%, {f1_neu*100:.2f}%, {f1_con*100:.2f}%) | Macro-F1: {macro_f1*100:.2f}%')\n",
    "\n",
    "\n",
    "path = f\"{ROOT_PATH}/nli_data/12-final.jsonl\"\n",
    "labeled_dataset = NLIDataset(path, tokenizer)\n",
    "labeled_loss, acc, f1_ent, f1_neu, f1_con = evaluate(\n",
    "    labeled_dataset, model, device, batch_size, no_labels=False, result_save_file= f\"{ROOT_PATH}/predictions/augmented/labeled_validation.jsonl\")\n",
    "macro_f1 = (f1_ent + f1_neu + f1_con) / 3\n",
    "print(f'Labeled dataset')\n",
    "print(f'Validation Loss: {labeled_loss:.3f} | Accuracy: {acc*100:.2f}%')\n",
    "print(f'F1: ({f1_ent*100:.2f}%, {f1_neu*100:.2f}%, {f1_con*100:.2f}%) | Macro-F1: {macro_f1*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "executionInfo": {
     "elapsed": 420,
     "status": "ok",
     "timestamp": 1680701206548,
     "user": {
      "displayName": "Prophecy Gaming PrG",
      "userId": "14056781264544618042"
     },
     "user_tz": -120
    },
    "id": "ZTVBr9G3jcUP",
    "outputId": "72d8d75b-19c7-4700-8cef-9ad552bb21d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>validation</td>\n",
       "      <td>base_model</td>\n",
       "      <td>77.08%</td>\n",
       "      <td>77.01%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>validation</td>\n",
       "      <td>augmented_model</td>\n",
       "      <td>76.88%</td>\n",
       "      <td>76.77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>labeled</td>\n",
       "      <td>base_model</td>\n",
       "      <td>65.00%</td>\n",
       "      <td>62.94%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>labeled</td>\n",
       "      <td>augmented_model</td>\n",
       "      <td>66.00%</td>\n",
       "      <td>64.05%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset            model accuracy macro-f1\n",
       "0  validation       base_model   77.08%   77.01%\n",
       "1  validation  augmented_model   76.88%   76.77%\n",
       "2     labeled       base_model   65.00%   62.94%\n",
       "3     labeled  augmented_model   66.00%   64.05%"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [\n",
    "    {\"dataset\" : \"validation\", \"model\" : 'base_model', \"accuracy\" : \"77.08%\", \"macro-f1\" : \"77.01%\"},\n",
    "    {\"dataset\" : \"validation\", \"model\" : 'augmented_model', \"accuracy\" : \"76.88%\", \"macro-f1\" : \"76.77%\"},\n",
    "    {\"dataset\" : \"labeled\", \"model\" : 'base_model', \"accuracy\" : \"65.00%\", \"macro-f1\" : \"62.94%\"},\n",
    "    {\"dataset\" : \"labeled\", \"model\" : 'augmented_model', \"accuracy\" : \"66.00%\", \"macro-f1\" : \"64.05%\"}\n",
    "]\n",
    "import pandas as pd\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 36567.60it/s]\n"
     ]
    }
   ],
   "source": [
    "save_repo_base = f\"{ROOT_PATH}/predictions/labeled_validation.jsonl\"\n",
    "save_repo_augment = f\"{ROOT_PATH}/predictions/augmented/labeled_validation.jsonl\"\n",
    "predictions = []\n",
    "with jsonlines.open(save_repo_base, \"r\") as reader:\n",
    "    for sample in tqdm(reader.iter()):\n",
    "        predictions.append(sample)\n",
    "\n",
    "with jsonlines.open(save_repo_augment, \"r\") as reader:\n",
    "    for i, sample in enumerate(reader.iter()):\n",
    "        predictions[i].update({'prediction_augm' : sample['prediction']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8 label that get imporoved by augmentating the model\n",
      "Here are 3 of them : \n",
      "\n",
      "premise : These monies also help defray the cost of putting on activities for faculty and students such as the Herron Awards Night.,\n",
      "hypothesis : The money help pay for activities for staff and students.,\n",
      "prediction_base : contradiction,\n",
      "prediction_augm : entailment,\n",
      "label : entailment,\n",
      "\n",
      "premise : When a task lies at the outer edge of the child's current capabilities, more direct guidance is necessary to bring it within range of mastery.,\n",
      "hypothesis : If the child can't do the task, guiding them will allow them to potentially master it.,\n",
      "prediction_base : neutral,\n",
      "prediction_augm : entailment,\n",
      "label : entailment,\n",
      "\n",
      "premise : The data suggest that when a manufacturer chooses the same inventory policy for all products, its order-fulfillment rate for highly variable products is usually worse than for low variation products.,\n",
      "hypothesis : Manufacturer's with a blanket inventory policy had better order-fulfillment rates when dealing with highly variable products.,\n",
      "prediction_base : contradiction,\n",
      "prediction_augm : entailment,\n",
      "label : entailment,\n",
      "\n",
      "*********************************************************\n",
      "\n",
      "There are 7 label that get worsend by augmentating the model\n",
      "Here are 3 of them : \n",
      "\n",
      "premise : Hope you will be present.,\n",
      "hypothesis : We will be waiting for you.,\n",
      "prediction_base : entailment,\n",
      "prediction_augm : neutral,\n",
      "label : entailment,\n",
      "\n",
      "premise : The upcoming year offers even more exciting opportunities.,\n",
      "hypothesis : We are not expecting more exciting opportunities this upcoming year,,\n",
      "prediction_base : contradiction,\n",
      "prediction_augm : neutral,\n",
      "label : contradiction,\n",
      "\n",
      "premise : By 1793, the firm of Almy, Brown and Slater was operating a seventy-two-spindle mill, producing high-quality yarn.,\n",
      "hypothesis : The mill produced woven doormats.,\n",
      "prediction_base : contradiction,\n",
      "prediction_augm : neutral,\n",
      "label : contradiction,\n"
     ]
    }
   ],
   "source": [
    "disagreements = [pred for pred in predictions if pred['prediction'] != pred['prediction_augm']]\n",
    "improvments = [pred for pred in predictions if pred['prediction'] != pred['prediction_augm'] and pred['prediction_augm'] == pred['label']]\n",
    "reduction = [pred for pred in predictions if pred['prediction'] != pred['prediction_augm'] and pred['prediction'] == pred['label']]\n",
    "\n",
    "\n",
    "n = 3\n",
    "data = improvments\n",
    "print(f\"There are {len(data)} label that get imporoved by augmentating the model\")\n",
    "print(f\"Here are {n} of them : \")\n",
    "for i in np.random.randint(0, len(data)-1, size =n) :\n",
    "    print(f\"\"\"\n",
    "premise : {data[i]['premise']},\n",
    "hypothesis : {data[i]['hypothesis']},\n",
    "prediction_base : {data[i]['prediction']},\n",
    "prediction_augm : {data[i]['prediction_augm']},\n",
    "label : {data[i]['label']},\"\"\")\n",
    "data = reduction\n",
    "print(f\"\\n*********************************************************\\n\")\n",
    "print(f\"There are {len(data)} label that get worsend by augmentating the model\")\n",
    "print(f\"Here are {n} of them : \")\n",
    "for i in np.random.randint(0, len(data)-1, size =n) :\n",
    "    print(f\"\"\"\n",
    "premise : {data[i]['premise']},\n",
    "hypothesis : {data[i]['hypothesis']},\n",
    "prediction_base : {data[i]['prediction']},\n",
    "prediction_augm : {data[i]['prediction_augm']},\n",
    "label : {data[i]['label']},\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNVMPjQTiesa"
   },
   "source": [
    "**Answer** : Despite using an augmented dataset, our new model has not shown a significant improvement. Instead, we have observed slightly worse results on the validation set, and a slight increase on the labeled dataset. \n",
    "\n",
    "This outcome was unexpected, as we had hoped for a significant improvement in performance. One possible explanation for this could be that by augmenting the data, the sentences have been altered, which may have impacted the inference process and led the model to learn incorrect inferences.\n",
    "\n",
    "In the above you can see 3 sample that get improved by augmenting the dataset and 3 sample that get worsend. What is interesting to see is that sample that are affected badly by the augmentation of the dataset are mostly samples with small sentences (at least in the hypothesis). This might be explained by the fact when we removed words in deletion, we affected the meaning of the sentences and then the small sentences get affected.\n",
    "\n",
    "The examples provided above demonstrate that augmenting the dataset improved the performance for some samples, while it worsened it for others. Notably, it is interesting to observe that the samples that were negatively impacted by the dataset augmentation were mostly those with shorter sentences (at least in the hypothesis). This observation can be explained by the fact that when we removed words through deletion, the meaning of the sentences may have been altered, which results in worse results for short sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M3CIeN_kaOQl"
   },
   "source": [
    "### **5 Upload Your Notebook, Data and Models**\n",
    "\n",
    "Please **rename** your filled jupyter notebook as **your Sciper number** and upload it to your GitHub Classroom repository, **with all cells run and output results shown**.\n",
    "\n",
    "**Note:** We are **not** responsible for re-running the cells in your notebook.\n",
    "\n",
    "Please also submit all your processed (e.g., anotated and augmented) datasets, as well as all your trained models in Task 1 and Task 4, in your GitHub Classroom repository.\n",
    "\n",
    "The datasets and models that you need to submit include:\n",
    "\n",
    "**1. The best model checkpoint you trained in the Section 1.2 \"Start Training and Validation!\"**\n",
    "\n",
    "**2. The best model prediction results in the Section 1.2 \"Fine-Grained Validation\"**\n",
    "\n",
    "**3. Your annotated test dataset in the Section 3.2 \"Annotate Your 100 Datapoints with Partner(s)\"**\n",
    "\n",
    "**4. Your augmented training data and best model checkpoint in the Section 4.2 \"Augment Your Model\"**\n",
    "\n",
    "**Note:** You may need to use [GitHub LFS](https://edstem.org/eu/courses/379/discussion/27240) for submitting large files."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "006a5e58dfd04454a12c9c3553e1a74a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "098e09c79c464eca88bb080e712f9bdc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a8a2757aa5845fd81a46d7e56afe34f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0d290adf55044765b04677404ee34408": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_26fe01c5e2f84edea87320605a97b090",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3d7e9c589ec74e1a948948ccc51a443a",
      "value": 1
     }
    },
    "0ddc6de3b3c748bc89d1aeae1a9d8789": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0fea13c3d8f7445984143e42c3067ea2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1cd29c3803774be6a8c802a991dbf3a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61793d0782324c50a846e20157c6c384",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_cf281efef9ee4a8599726cfa8127d73d",
      "value": " 268M/268M [00:02&lt;00:00, 90.5MB/s]"
     }
    },
    "26fe01c5e2f84edea87320605a97b090": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "2a10aba59c4a4b9f8b13718d40808ea9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b9fc7456171641d183303399ddb86b3d",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e94b9b7d472c41dba0d85df26d466a38",
      "value": 28
     }
    },
    "3d7e9c589ec74e1a948948ccc51a443a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "475f7f3aeafe4820a5b2764953732603": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "499bf00fe9e84ce983468005f01fa226": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c2a86505c3a426394479d677f009493": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50a6c35c0cda4a96b35aa723708fc93d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_823e4161906140c1b1f93429dc2ea6b0",
      "max": 483,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_641afe3e9b404a0485b7b2afce92e643",
      "value": 483
     }
    },
    "5915dd246fca4960a5e53f9639ea2892": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b89f1fa3cf54b8eb3e9e5707b5d63f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_499bf00fe9e84ce983468005f01fa226",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_0ddc6de3b3c748bc89d1aeae1a9d8789",
      "value": " 232k/? [00:00&lt;00:00, 6.94MB/s]"
     }
    },
    "607cdea2938c4b1b9f8106cb7de44661": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_098e09c79c464eca88bb080e712f9bdc",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_0a8a2757aa5845fd81a46d7e56afe34f",
      "value": "Downloading (â€¦)lve/main/config.json: 100%"
     }
    },
    "61793d0782324c50a846e20157c6c384": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61f44c01830a453495fa23c33122ffbb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a1ae95d1d72044dd954ac4ee0cd0b64d",
       "IPY_MODEL_0d290adf55044765b04677404ee34408",
       "IPY_MODEL_5b89f1fa3cf54b8eb3e9e5707b5d63f3"
      ],
      "layout": "IPY_MODEL_4c2a86505c3a426394479d677f009493"
     }
    },
    "641afe3e9b404a0485b7b2afce92e643": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "69db31922bfb483280f97b9e43b72943": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e2ab23538e4470bb69fb69e6d89f356": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_475f7f3aeafe4820a5b2764953732603",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_91d4740859cd48258e1d8f79d0bc4bfd",
      "value": "Downloading (â€¦)&quot;pytorch_model.bin&quot;;: 100%"
     }
    },
    "728d854d83964871b956bdb904311ce8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "823e4161906140c1b1f93429dc2ea6b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82458bca0c2a45deb1d233428c2b955d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b0f047c6116461cb3747d23c953a483": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "90b24e100fde4cb0b2f1884878468a59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d4db477adc7142bda8bd5bde3785df00",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_8b0f047c6116461cb3747d23c953a483",
      "value": "Downloading (â€¦)okenizer_config.json: 100%"
     }
    },
    "91d4740859cd48258e1d8f79d0bc4bfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "92535a4bc32f4068bb39caad245750b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95bfc4a3a197498e9858b5c4418d0c54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_90b24e100fde4cb0b2f1884878468a59",
       "IPY_MODEL_2a10aba59c4a4b9f8b13718d40808ea9",
       "IPY_MODEL_f412d59730dc486fb165e41ff04610de"
      ],
      "layout": "IPY_MODEL_69db31922bfb483280f97b9e43b72943"
     }
    },
    "a1ae95d1d72044dd954ac4ee0cd0b64d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5915dd246fca4960a5e53f9639ea2892",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_006a5e58dfd04454a12c9c3553e1a74a",
      "value": "Downloading (â€¦)solve/main/vocab.txt: "
     }
    },
    "b694aa8c38524f88bed1ad6adef91dfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b9fc7456171641d183303399ddb86b3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2347e18eb3d44fe9b20149d29c6021c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6e2ab23538e4470bb69fb69e6d89f356",
       "IPY_MODEL_d080fded4e234838b93b844cc0e8c1ee",
       "IPY_MODEL_1cd29c3803774be6a8c802a991dbf3a2"
      ],
      "layout": "IPY_MODEL_cf0ae0ae788c42dd8f8aa387410d6bcf"
     }
    },
    "c6b58aa264474d97bad77ce4c3c20dc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cf0ae0ae788c42dd8f8aa387410d6bcf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf281efef9ee4a8599726cfa8127d73d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d080fded4e234838b93b844cc0e8c1ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92535a4bc32f4068bb39caad245750b6",
      "max": 267967963,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c6b58aa264474d97bad77ce4c3c20dc0",
      "value": 267967963
     }
    },
    "d4db477adc7142bda8bd5bde3785df00": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dec359686a06498697b1922c7ca75e2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82458bca0c2a45deb1d233428c2b955d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_728d854d83964871b956bdb904311ce8",
      "value": " 483/483 [00:00&lt;00:00, 19.9kB/s]"
     }
    },
    "e94b9b7d472c41dba0d85df26d466a38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ed1395f1c2f64f1d948e314bdfa4efcb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f412d59730dc486fb165e41ff04610de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed1395f1c2f64f1d948e314bdfa4efcb",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b694aa8c38524f88bed1ad6adef91dfe",
      "value": " 28.0/28.0 [00:00&lt;00:00, 1.09kB/s]"
     }
    },
    "fb1cb9be9f2d4794aa3f5a6ef64fc303": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_607cdea2938c4b1b9f8106cb7de44661",
       "IPY_MODEL_50a6c35c0cda4a96b35aa723708fc93d",
       "IPY_MODEL_dec359686a06498697b1922c7ca75e2b"
      ],
      "layout": "IPY_MODEL_0fea13c3d8f7445984143e42c3067ea2"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
